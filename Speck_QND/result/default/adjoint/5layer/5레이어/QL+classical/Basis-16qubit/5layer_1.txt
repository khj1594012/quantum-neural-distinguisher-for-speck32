hj@DESKTOP-6RMLMKU:~/SPECK$ python3 16qubit_5layers.py
2023-03-06 16:05:12.986219: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2023-03-06 16:05:12.986702: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2023-03-06 16:05:30.930144: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2023-03-06 16:05:30.930629: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2023-03-06 16:05:30.930946: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (DESKTOP-6RMLMKU): /proc/driver/nvidia/version does not exist
2023-03-06 16:05:30.931499: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to
==================================================================================================
 input_1 (InputLayer)           [(None, 64)]         0           []

 tf.split (TFOpLambda)          [(None, 16),         0           ['input_1[0][0]']
                                 (None, 16),
                                 (None, 16),
                                 (None, 16)]

 keras_layer_1 (KerasLayer)     (None, 16)           80          ['tf.split[0][0]']

 keras_layer_2 (KerasLayer)     (None, 16)           80          ['tf.split[0][1]']

 keras_layer_3 (KerasLayer)     (None, 16)           80          ['tf.split[0][2]']

 keras_layer_4 (KerasLayer)     (None, 16)           80          ['tf.split[0][3]']

 tf.concat (TFOpLambda)         (None, 64)           0           ['keras_layer_1[0][0]',
                                                                  'keras_layer_2[0][0]',
                                                                  'keras_layer_3[0][0]',
                                                                  'keras_layer_4[0][0]']

 dense (Dense)                  (None, 64)           4160        ['tf.concat[0][0]']

 batch_normalization (BatchNorm  (None, 64)          256         ['dense[0][0]']
 alization)

 activation (Activation)        (None, 64)           0           ['batch_normalization[0][0]']

 dense_1 (Dense)                (None, 1)            65          ['activation[0][0]']

==================================================================================================
Total params: 4,801
Trainable params: 4,673
Non-trainable params: 128
__________________________________________________________________________________________________
Epoch 1/10
313/313 - 7742s - loss: 0.7186 - acc: 0.5024 - val_loss: 0.6941 - val_acc: 0.5404 - 7742s/epoch - 25s/step
Epoch 2/10

313/313 - 7579s - loss: 0.6663 - acc: 0.5937 - val_loss: 0.6394 - val_acc: 0.6444 - 7579s/epoch - 24s/step
^@Epoch 3/10

313/313 - 7743s - loss: 0.6038 - acc: 0.6954 - val_loss: 0.5825 - val_acc: 0.7034 - 7743s/epoch - 25s/step
Epoch 4/10
313/313 - 7786s - loss: 0.5713 - acc: 0.7196 - val_loss: 0.5720 - val_acc: 0.7132 - 7786s/epoch - 25s/step
Epoch 5/10

313/313 - 7893s - loss: 0.5637 - acc: 0.7176 - val_loss: 0.5702 - val_acc: 0.7144 - 7893s/epoch - 25s/step
Epoch 6/10
313/313 - 7947s - loss: 0.5559 - acc: 0.7274 - val_loss: 0.5703 - val_acc: 0.7140 - 7947s/epoch - 25s/step
Epoch 7/10

313/313 - 7983s - loss: 0.5509 - acc: 0.7319 - val_loss: 0.5714 - val_acc: 0.7100 - 7983s/epoch - 26s/step
Epoch 8/10
313/313 - 9015s - loss: 0.5418 - acc: 0.7368 - val_loss: 0.5731 - val_acc: 0.7124 - 9015s/epoch - 29s/step
Epoch 9/10
313/313 - 8783s - loss: 0.5396 - acc: 0.7365 - val_loss: 0.5745 - val_acc: 0.7132 - 8783s/epoch - 28s/step
Epoch 10/10


313/313 - 7901s - loss: 0.5351 - acc: 0.7415 - val_loss: 0.5742 - val_acc: 0.7110 - 7901s/epoch - 25s/step
32/32 [==============================] - 151s 5s/step
0.74